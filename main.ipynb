{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGxn_zQ1Ghlp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ckwFv_1OGhlu"
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ENo_1bfFGhlv"
   },
   "outputs": [],
   "source": [
    "pil_to_tensor_transform = transforms.ToTensor()\n",
    "normalizer = transforms.Normalize((0.1307,), (0.3081,))\n",
    "\n",
    "compose = transforms.Compose([\n",
    "    pil_to_tensor_transform,\n",
    "    normalizer,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "oD99KcnUGhlx",
    "outputId": "0b2ebd04-c607-4189-ac27-f93de7bf9230",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./datasets\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "           )\n",
      "\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./datasets\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# Train set\n",
    "train_set = datasets.MNIST('./datasets', train=True, download=True, transform=compose)\n",
    "# Test set\n",
    "test_set = datasets.MNIST('./datasets', train=False, download=True, transform=compose)\n",
    "\n",
    "print(train_set)\n",
    "print()\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "PaI3tuu4Ghl0",
    "outputId": "65f7d022-762a-41dd-fdfd-7f4fc4a00ead"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(tensor):\n",
    "    plt.imshow(tensor.squeeze(), cmap='binary')\n",
    "    plt.show()\n",
    "    \n",
    "imshow(train_set[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1h8GzEW4Ghl2"
   },
   "source": [
    "### Datasets loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBmFtQfmGhl3"
   },
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xRh0dcmvGhl5"
   },
   "outputs": [],
   "source": [
    "# Train set loader\n",
    "train_set_loader = data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "# Test set loader\n",
    "test_set_loader = data.DataLoader(test_set, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nmexReNwGhl8"
   },
   "source": [
    "## Squashing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9PmRd96TGhl9"
   },
   "outputs": [],
   "source": [
    "def squash(v):\n",
    "    dot_prod = v.T @ v\n",
    "    \n",
    "    if dot_prod == 0:\n",
    "        return torch.zeros_like(v)\n",
    "    \n",
    "    unit_v = v / torch.sqrt(dot_prod)\n",
    "    squashing = dot_prod / (dot_prod+1)\n",
    "    \n",
    "    return squashing * unit_v\n",
    "\n",
    "def squash_relu(v, eps=0.00):\n",
    "    norm = v.norm()\n",
    "    \n",
    "    if norm == 0:\n",
    "        return torch.zeros_like(v)\n",
    "    \n",
    "    unit_v = v / norm\n",
    "    v = torch.tensor([\n",
    "        a if a > 0 else eps*a for a in v\n",
    "    ])\n",
    "    squashing = v.norm()\n",
    "    \n",
    "    return squashing * unit_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "qbXQzsCnGhl_",
    "outputId": "09a66b18-8ac0-4821-b568-051c97c00e32"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.linspace(-5, 5)\n",
    "\n",
    "y = [squash(torch.tensor([v]))[0] for v in x]\n",
    "y_relu = [squash_relu(torch.tensor([v]))[0] for v in x]\n",
    "\n",
    "plt.plot(x, y);\n",
    "plt.plot(x, y_relu);\n",
    "\n",
    "plt.legend(['Squashing', 'Squashing_ReLU']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JlWcUBstGhmB"
   },
   "source": [
    "## Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkpGvbwhGhmB"
   },
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    '''A Convolutional Layer'''\n",
    "    \n",
    "    def __init__(self, in_channels=1, out_channels=256, kernel_size=9):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.relu(self.conv(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9E2-9leUGhmD"
   },
   "source": [
    "## Primary Capsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "spbtlb7YGhmE"
   },
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    '''Primary Capsules'''\n",
    "    \n",
    "    def __init__(self, num_capsules=32, in_channels=256, out_channels=8, kernel_size=9, stride=2):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "        \n",
    "        self.out_channels = out_channels\n",
    "        self.capsules = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride) for _ in range(num_capsules)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = []\n",
    "        \n",
    "        for capsule in self.capsules:\n",
    "            out = F.relu(capsule(x))\n",
    "            output.append(out)\n",
    "        \n",
    "        output = torch.stack(output, dim=1)\n",
    "        output = output.view(x.size(0), -1, self.out_channels)\n",
    "        \n",
    "        return self.activation(output)\n",
    "    \n",
    "    def activation(self, x):\n",
    "        '''Squash'''\n",
    "        \n",
    "        squared_norm = (x**2).sum(-1, keepdim=True) + 1e-18\n",
    "        squashing_coef = squared_norm / (1 + squared_norm)\n",
    "        \n",
    "        unit = x / torch.sqrt(squared_norm)\n",
    "        \n",
    "        return squashing_coef * unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39TBPL1lGhmI"
   },
   "source": [
    "## Digit Capsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ia2DiRS-GhmI"
   },
   "outputs": [],
   "source": [
    "class DigitCaps(nn.Module):\n",
    "    '''Digit Capsules'''\n",
    "    \n",
    "    def __init__(self, num_capsules=10, num_inputs_per_capsule=32*6*6, in_dim=8, out_dim=16, r=3, cuda=False):\n",
    "        super(DigitCaps, self).__init__()\n",
    "        \n",
    "        self.num_capsules = num_capsules\n",
    "        self.num_inputs_per_capsule = num_inputs_per_capsule\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.r = r\n",
    "        self.cuda = cuda\n",
    "        \n",
    "        self.W = nn.Parameter(\n",
    "            torch.randn(num_inputs_per_capsule, num_capsules, out_dim, in_dim, dtype=torch.float32)\n",
    "        )\n",
    "    \n",
    "    def routing(self, u_hat):\n",
    "        '''Dynamic Routing (Routing By Agreement)'''\n",
    "        \n",
    "        b_ij = torch.zeros(self.num_inputs_per_capsule, self.num_capsules, dtype=torch.float32)\n",
    "\n",
    "        if self.cuda and torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "        b_ij = b_ij.to(device)\n",
    "        \n",
    "        for iteration in range(self.r):\n",
    "            c_ij = F.softmax(b_ij, dim=0)\n",
    "            c_ij = torch.stack([c_ij] * u_hat.size(0), dim=0).unsqueeze(3).unsqueeze(4)\n",
    "            \n",
    "            s_j = (u_hat @ c_ij).sum(dim=1)\n",
    "            v_j = self.activation(s_j)\n",
    "            \n",
    "            if iteration < self.r - 1:\n",
    "                d = u_hat.transpose(3, 4) @ torch.stack([v_j] * self.num_inputs_per_capsule, dim=1)\n",
    "                b_ij = b_ij + d.squeeze(4).squeeze(3).mean(dim=0)\n",
    "            \n",
    "        return v_j.squeeze(3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Get the dimensions right\n",
    "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
    "        W = torch.stack([self.W] * x.size(0), dim=0)\n",
    "        \n",
    "        # Affine Transformation\n",
    "        u_hat = W @ x\n",
    "        \n",
    "        # Dynamic Routing\n",
    "        return self.routing(u_hat)\n",
    "        \n",
    "    def activation(self, x):\n",
    "        '''Squash'''\n",
    "        \n",
    "        squared_norm = (x**2).sum(-1, keepdim=True) + 1e-18\n",
    "        squashing_coef = squared_norm / (1 + squared_norm)\n",
    "        \n",
    "        unit = x / torch.sqrt(squared_norm)\n",
    "        \n",
    "        return squashing_coef * unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = DigitCaps()(PrimaryCaps()(ConvLayer()(torch.randn(64, 1, 28, 28))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mkbIC9zeGhmN"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    '''Capsule Net Decoder'''\n",
    "    \n",
    "    def __init__(self, in_dim=16, out_dim=28*28):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.reconstruction_layers = nn.Sequential(\n",
    "            nn.Linear(in_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, out_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        most_active_idx = torch.norm(x, dim=2).argmax(dim=1)\n",
    "        x_masked = torch.stack([x[i, idx] for i, idx in zip(range(x.size(0)), most_active_idx)], dim=0)\n",
    "        \n",
    "        return self.reconstruction_layers(x_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_o5W0RsGhmR"
   },
   "source": [
    "# Capsule Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t9dJYIdxGhmR"
   },
   "outputs": [],
   "source": [
    "class CapsNet(nn.Module):\n",
    "    '''Capsule Network'''\n",
    "    \n",
    "    def __init__(self, cuda=False):\n",
    "        super(CapsNet, self).__init__()\n",
    "        \n",
    "        self.conv_layer = ConvLayer()\n",
    "        self.primary_capsules = PrimaryCaps()\n",
    "        self.digit_capsules = DigitCaps(cuda=cuda)\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = self.primary_capsules(x)\n",
    "        x = self.digit_capsules(x)\n",
    "        \n",
    "        reconstruction = self.decoder(x)\n",
    "        \n",
    "        return x, reconstruction\n",
    "    \n",
    "    @staticmethod\n",
    "    def loss(output, targets, reconstruction, images):\n",
    "        return CapsNet.margin_loss(output, targets) + \\\n",
    "            CapsNet.reconstruction_loss(reconstruction, images)\n",
    "\n",
    "    @staticmethod\n",
    "    def margin_loss(output, targets, lmbd=0.5, m_plus=0.9, m_minus=0.1):\n",
    "        probs = torch.norm(output, dim=2)\n",
    "        left = F.relu(m_plus - probs)**2\n",
    "        right = F.relu(probs - m_minus)**2\n",
    "\n",
    "        most_active_idx = probs.argmax(dim=1)\n",
    "        T = (most_active_idx == targets).float().unsqueeze(1)\n",
    "        loss = T * left + lmbd*(1 - T) * right\n",
    "        \n",
    "        return loss.sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def reconstruction_loss(reconstruction, images, criterion=nn.MSELoss()):\n",
    "        return criterion(reconstruction, images.view(reconstruction.size(0), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8FyB69OGhmd"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING CPU\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = True\n",
    "EPOCHS = 30\n",
    "\n",
    "if USE_CUDA and torch.cuda.is_available():\n",
    "    print('USING CUDA')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('USING CPU')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "capsnet = CapsNet(cuda=USE_CUDA)\n",
    "capsnet = capsnet.to(device)\n",
    "optimizer = optim.SGD(capsnet.parameters(), lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "98fL8qNRGhmd",
    "outputId": "71dec2ff-8e26-4a71-8389-1f959063a072",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== TRAIN ==========\n",
      "==> EPOCH[1] (1/469): LOSS: 57.88624572753906 ACCURACY: 0.0546875\n",
      "==> EPOCH[1] (2/469): LOSS: 90.25154113769531 ACCURACY: 0.0859375\n",
      "==> EPOCH[1] (3/469): LOSS: 82.15869140625 ACCURACY: 0.078125\n",
      "==> EPOCH[1] (4/469): LOSS: 114.5154800415039 ACCURACY: 0.109375\n",
      "==> EPOCH[1] (5/469): LOSS: 57.89715576171875 ACCURACY: 0.0546875\n",
      "==> EPOCH[1] (6/469): LOSS: 65.95892333984375 ACCURACY: 0.0625\n",
      "==> EPOCH[1] (7/469): LOSS: 41.70224380493164 ACCURACY: 0.0390625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-226bd8f7512c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmost_active_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Optim step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capsnets-0ttV1p5F/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capsnets-0ttV1p5F/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    \n",
    "    print()\n",
    "    print('='*10, 'TRAIN', '='*10)\n",
    "    capsnet.train()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    \n",
    "    for i, batch in enumerate(train_set_loader, 1):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Load the batch\n",
    "        images, targets = batch\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        output, reconstruction = capsnet(images)\n",
    "        # Compute loss\n",
    "        loss = CapsNet.loss(output, targets, reconstruction, images)\n",
    "        # Compute accuracy\n",
    "        most_active_idx = output.norm(dim=2).argmax(dim=1)\n",
    "        accuracy = torch.sum((most_active_idx == targets)).item() / targets.size(0)\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        # Optim step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Add loss\n",
    "        running_loss += loss.item()\n",
    "        # Add accuracy\n",
    "        running_accuracy += accuracy\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f'==> EPOCH[{epoch}] ({i}/{len(train_set_loader)}): LOSS: {loss.item()} ACCURACY: {accuracy}')\n",
    "            \n",
    "    print(f'=====> EPOCH[{epoch}] Completed: \\\n",
    "        Avg. LOSS: {running_loss/len(train_set_loader)} Avg. ACCURACY {running_accuracy/len(train_set_loader)}')\n",
    "    \n",
    "    print()\n",
    "    print('='*10, 'EVAL', '='*10)\n",
    "    capsnet.eval()\n",
    "    running_accuracy = 0.0\n",
    "    \n",
    "    for i, batch in enumerate(test_set_loader, 1):\n",
    "\n",
    "        # Load the batch\n",
    "        images, targets = batch\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Forward\n",
    "            output, reconstruction = capsnet(images)\n",
    "            most_active_idx = output.norm(dim=2).argmax(dim=1)\n",
    "            running_accuracy += torch.sum((most_active_idx == targets)).item() / targets.size(0)\n",
    "\n",
    "    print(f'=====> EPOCH[{epoch}]: AVG. ACCURACY: {running_accuracy/len(test_set_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "capsnet/main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

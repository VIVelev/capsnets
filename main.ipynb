{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "capsnet/main.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGxn_zQ1Ghlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "USE_CUDA = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckwFv_1OGhlu",
        "colab_type": "text"
      },
      "source": [
        "## Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENo_1bfFGhlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pil_to_tensor_transform = transforms.ToTensor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oD99KcnUGhlx",
        "colab_type": "code",
        "outputId": "0b2ebd04-c607-4189-ac27-f93de7bf9230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Train set\n",
        "train_set = datasets.MNIST('./datasets', train=True, download=True, transform=pil_to_tensor_transform)\n",
        "# Test set\n",
        "test_set = datasets.MNIST('./datasets', train=False, download=True, transform=pil_to_tensor_transform)\n",
        "\n",
        "print(train_set)\n",
        "print()\n",
        "print(test_set)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./datasets\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./datasets\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaI3tuu4Ghl0",
        "colab_type": "code",
        "outputId": "65f7d022-762a-41dd-fdfd-7f4fc4a00ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "def imshow(tensor):\n",
        "    plt.imshow(tensor.squeeze(), cmap='binary')\n",
        "    plt.show()\n",
        "    \n",
        "imshow(train_set[0][0])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h8GzEW4Ghl2",
        "colab_type": "text"
      },
      "source": [
        "### Datasets loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBmFtQfmGhl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARAMS\n",
        "BATCH_SIZE = 64\n",
        "TEST_BATCH_SIZE = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRh0dcmvGhl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train set loader\n",
        "train_set_loader = data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "# Test set loader\n",
        "test_set_loader = data.DataLoader(test_set, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjk7Aqk_Ghl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmexReNwGhl8",
        "colab_type": "text"
      },
      "source": [
        "## Squashing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PmRd96TGhl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def squash(v):\n",
        "    dot_prod = v.T @ v\n",
        "    \n",
        "    if dot_prod == 0:\n",
        "        return torch.zeros_like(v)\n",
        "    \n",
        "    unit_v = v / torch.sqrt(dot_prod)\n",
        "    squashing = dot_prod / (dot_prod+1)\n",
        "    \n",
        "    return squashing * unit_v\n",
        "\n",
        "def squash_relu(v, eps=0.00):\n",
        "    norm = v.norm()\n",
        "    \n",
        "    if norm == 0:\n",
        "        return torch.zeros_like(v)\n",
        "    \n",
        "    unit_v = v / norm\n",
        "    v = torch.tensor([\n",
        "        a if a > 0 else eps*a for a in v\n",
        "    ])\n",
        "    squashing = v.norm()\n",
        "    \n",
        "    return squashing * unit_v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbXQzsCnGhl_",
        "colab_type": "code",
        "outputId": "09a66b18-8ac0-4821-b568-051c97c00e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "x = torch.linspace(-5, 5)\n",
        "\n",
        "y = [squash(torch.tensor([v]))[0] for v in x]\n",
        "y_relu = [squash_relu(torch.tensor([v]))[0] for v in x]\n",
        "\n",
        "plt.plot(x, y);\n",
        "plt.plot(x, y_relu);\n",
        "\n",
        "plt.legend(['Squashing', 'Squashing_ReLU']);"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlWcUBstGhmB",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkpGvbwhGhmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvLayer(nn.Module):\n",
        "    '''A Convolutional Layer'''\n",
        "    \n",
        "    def __init__(self, in_channels=1, out_channels=256, kernel_size=9):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        \n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return F.relu(self.conv(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E2-9leUGhmD",
        "colab_type": "text"
      },
      "source": [
        "## Primary Capsules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spbtlb7YGhmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PrimaryCaps(nn.Module):\n",
        "    '''Primary Capsules'''\n",
        "    \n",
        "    def __init__(self, num_capsules=32, in_channels=256, out_channels=8, kernel_size=9, stride=2):\n",
        "        super(PrimaryCaps, self).__init__()\n",
        "        \n",
        "        self.capsules = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride) for _ in range(num_capsules)\n",
        "        ])\n",
        "    \n",
        "    def forward(self, x):\n",
        "        output = []\n",
        "        \n",
        "        for capsule in self.capsules:\n",
        "            out = F.relu(capsule(x))\n",
        "            output.append(out)\n",
        "        \n",
        "        output = torch.stack(output, dim=1)\n",
        "        output = output.view(x.size(0), 32*6*6, 8)\n",
        "        \n",
        "        return self.activation(output)\n",
        "    \n",
        "    def activation(self, x, squash=squash):\n",
        "        output = torch.zeros_like(x)\n",
        "        \n",
        "        for i in range(x.size(0)):\n",
        "            for j in range(x.size(1)):\n",
        "                output[i][j][:] = squash(x[i][j][:])\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39TBPL1lGhmI",
        "colab_type": "text"
      },
      "source": [
        "## Digit Capsules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia2DiRS-GhmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DigitCaps(nn.Module):\n",
        "    '''Digit Capsules'''\n",
        "    \n",
        "    def __init__(self, num_capsules=10, num_inputs_per_capsule=32*6*6, in_dim=8, out_dim=16, r=3):\n",
        "        super(DigitCaps, self).__init__()\n",
        "        \n",
        "        self.num_capsules = num_capsules\n",
        "        self.num_inputs_per_capsule = num_inputs_per_capsule\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.r = r\n",
        "        \n",
        "        self.W = nn.Parameter(torch.randn(num_inputs_per_capsule, in_dim, out_dim, dtype=torch.float32))\n",
        "    \n",
        "    def routing(self, U_hat):\n",
        "        b_ij = torch.zeros(self.num_inputs_per_capsule, self.num_capsules, dtype=torch.float32)\n",
        "        if USE_CUDA and torch.cuda.is_available():\n",
        "            b_ij = b_ij.to(torch.device('cuda'))\n",
        "        else:\n",
        "            b_ij = b_ij.to(torch.device('cpu'))\n",
        "\n",
        "        v_j = None\n",
        "        \n",
        "        for iteration in range(self.r):\n",
        "            c_ij = F.softmax(b_ij, dim=1)\n",
        "            s_j = c_ij.T.unsqueeze(0) @ U_hat\n",
        "            v_j = self.activation(s_j)\n",
        "            \n",
        "            if iteration < self.r-1:\n",
        "                b_ij = b_ij + (U_hat @ v_j.view(-1, self.out_dim, self.num_capsules)).mean(dim=0)\n",
        "            \n",
        "        return v_j\n",
        "        \n",
        "    def forward(self, x):\n",
        "        U_hat = []\n",
        "        U_hat_i = []\n",
        "        \n",
        "        for u in x:\n",
        "            for i in range(self.num_inputs_per_capsule):\n",
        "                U_hat_i.append((self.W[i].T @ u[i]).unsqueeze(0))\n",
        "            \n",
        "            U_hat.append(torch.cat(U_hat_i).unsqueeze(0))\n",
        "            U_hat_i = []\n",
        "        \n",
        "        U_hat = torch.cat(U_hat)\n",
        "        \n",
        "        return self.routing(U_hat)\n",
        "    \n",
        "    def activation(self, x, squash=squash):\n",
        "        output = torch.zeros_like(x)\n",
        "        \n",
        "        for i in range(x.size(0)):\n",
        "            for j in range(x.size(1)):\n",
        "                output[i][j][:] = squash(x[i][j][:])\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gFo8kz5GhmM",
        "colab_type": "text"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkbIC9zeGhmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    '''Capsule Net Decoder'''\n",
        "    \n",
        "    def __init__(self, in_dim=16, out_dim=28*28):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.reconstruction_layers = nn.Sequential(\n",
        "            nn.Linear(in_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, out_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        most_active_idx = torch.norm(x, dim=2).argmax(dim=1)\n",
        "        x_masked = torch.cat([x[i, idx].unsqueeze(0) for i, idx in zip(range(x.size(0)), most_active_idx)])\n",
        "        \n",
        "        return self.reconstruction_layers(x_masked)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_o5W0RsGhmR",
        "colab_type": "text"
      },
      "source": [
        "# Capsule Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9dJYIdxGhmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CapsNet(nn.Module):\n",
        "    '''Capsule Network'''\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(CapsNet, self).__init__()\n",
        "        \n",
        "        self.conv_layer = ConvLayer()\n",
        "        self.primary_capsules = PrimaryCaps()\n",
        "        self.digit_capsules = DigitCaps()\n",
        "        self.decoder = Decoder()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv_layer(x)\n",
        "        x = self.primary_capsules(x)\n",
        "        x = self.digit_capsules(x)\n",
        "        \n",
        "        reconstruction = self.decoder(x)\n",
        "        \n",
        "        return x, reconstruction\n",
        "    \n",
        "    @staticmethod\n",
        "    def loss(output, targets, reconstruction, images):\n",
        "        return CapsNet.margin_loss(output, targets) + \\\n",
        "            CapsNet.reconstruction_loss(reconstruction, images)\n",
        "\n",
        "    @staticmethod\n",
        "    def margin_loss(output, targets, lmbd=0.5, m_plus=0.9, m_minus=0.1):\n",
        "        probs = torch.norm(output, dim=2)\n",
        "        left = F.relu(m_plus - probs)**2\n",
        "        right = F.relu(probs - m_minus)**2\n",
        "\n",
        "        most_active_idx = probs.argmax(dim=1)\n",
        "        T = (most_active_idx == targets).int().unsqueeze(1)\n",
        "        loss = T * left + lmbd*(1 - T) * right\n",
        "        \n",
        "        return loss.sum()\n",
        "    \n",
        "    @staticmethod\n",
        "    def reconstruction_loss(reconstruction, images, criterion=nn.MSELoss()):\n",
        "        return criterion(reconstruction, images.view(reconstruction.size(0), -1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8FyB69OGhmd",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98fL8qNRGhmd",
        "colab_type": "code",
        "outputId": "71dec2ff-8e26-4a71-8389-1f959063a072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "capsnet = CapsNet()\n",
        "optimizer = optim.Adam(capsnet.parameters(), lr=0.001)\n",
        "\n",
        "if USE_CUDA and torch.cuda.is_available():\n",
        "    print('USING CUDA')\n",
        "    capsnet = capsnet.to(torch.device('cuda'))\n",
        "else:\n",
        "    print('USING CPU')\n",
        "    capsnet = capsnet.to(torch.device('cpu'))\n",
        "\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    \n",
        "    print('='*10, 'TRAIN', '='*10)\n",
        "    capsnet.train()\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for i, batch in enumerate(train_set_loader, 1):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Load the batch\n",
        "        images, targets = batch\n",
        "        if USE_CUDA and torch.cuda.is_available():\n",
        "            images = images.to(torch.device('cuda'))\n",
        "            targets = targets.to(torch.device('cuda'))\n",
        "        \n",
        "        # Forward\n",
        "        output, reconstruction = capsnet(images)\n",
        "        # Compute loss\n",
        "        loss = CapsNet.loss(output, targets, reconstruction, images)\n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        # Optim step\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        if i % 1 == 0:\n",
        "            print(f'==> EPOCH[{epoch}] ({i}/{len(train_set_loader)}): LOSS: {loss.item()}')\n",
        "    print(f'=====> EPOCH[{epoch}] Completed: Avg. LOSS: {running_loss/len(train_set_loader)}')\n",
        "    \n",
        "    print('='*10, 'EVAL', '='*10)\n",
        "    capsnet.eval()\n",
        "    running_accuracy = 0.0\n",
        "    \n",
        "    for i, batch in enumerate(test_set_loader, 1):\n",
        "\n",
        "        # Load the batch\n",
        "        images, targets = batch\n",
        "        if USE_CUDA and torc.cuda.is_available():\n",
        "            images = images.to(torch.device('cuda'))\n",
        "            targets = targets.to(torch.device('cuda'))\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # Forward\n",
        "            output, reconstruction = capsnet(images)\n",
        "            most_active_idx = output.norm(dim=2).argmax(dim=1)\n",
        "            running_accuracy += torch.sum((most_active_idx == targets)) / targets.size(0)\n",
        "\n",
        "    print(f'=====> EPOCH[{epoch}]: ACCURACY: {running_accuracy/len(test_set_loader)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "USING CUDA\n",
            "========== TRAIN ==========\n",
            "==> EPOCH[1] (1/938): LOSS: 111.05752563476562\n",
            "==> EPOCH[1] (2/938): LOSS: 247.0171661376953\n",
            "==> EPOCH[1] (3/938): LOSS: 234.89208984375\n",
            "==> EPOCH[1] (4/938): LOSS: 238.92877197265625\n",
            "==> EPOCH[1] (5/938): LOSS: 218.6754608154297\n",
            "==> EPOCH[1] (6/938): LOSS: 238.88478088378906\n",
            "==> EPOCH[1] (7/938): LOSS: 230.77041625976562\n",
            "==> EPOCH[1] (8/938): LOSS: 230.74557495117188\n",
            "==> EPOCH[1] (9/938): LOSS: 226.6778564453125\n",
            "==> EPOCH[1] (10/938): LOSS: 222.62191772460938\n",
            "==> EPOCH[1] (11/938): LOSS: 238.79397583007812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "593lrvlcGhmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}